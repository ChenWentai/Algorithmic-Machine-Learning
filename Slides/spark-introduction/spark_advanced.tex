% \begin{frame}\frametitle{TODO}
% \begin{itemize}
%   \item Data partitioning
%   \item Broadcast Variables
%   \item Accumulators
%   \item MLLib
% \end{itemize}


\begin{frame}\frametitle{Accumulators (1)}
\begin{itemize}
	\item {\bf Underlying idea}
	\begin{itemize}
		\item Simple mechanism and syntax for aggregating values from worker nodes back to the driver program
	\end{itemize}

	\item {\bf Common uses}
	\begin{itemize}
		\item Count events that occur during job execution for debugging purposes
		\item Sharing state with the driver program
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Accumulators (2)}
\begin{itemize}
	\item {\bf Why another mechanism when we have \texttt{reduce()} or \texttt{collectAs()} calls?}
	\begin{itemize}
		\item Accumulators are a simple way to aggregate values that are generated at different scale or granularity than that of an RDD
		\item Workers cannot read the value of accumulators, they can only write to it $\to$ they are \emph{write-only} variables from the workers' perspective
	\end{itemize}

	\item {\bf What about failures?}
	\begin{itemize}
		\item Accumulators used in actions: Spark applies each task's update to each accumulator only once $\to$ we must put them inside an action like \texttt{foreach()} to achieve correctness.
		\item Accumulators used in transformations: there are no guarantees, hence an accumulator update within a transformation can occur more than once
	\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}\frametitle{Accumulators (3)}
{\bf Basic work-flow to use accumulators:}

\vspace{20pt}

\begin{itemize}
	\item Create them in the driver by calling the \texttt{SparkContext.accumulator(initial Value)} method, which produces an accumulator holding an initial value. The return type is an \texttt{org.apache.spark.Accumulator[T]} object, where T is the type of initialValue
	\item Worker code in Spark closures can add to the accumulator with its \texttt{+=} method
	\item The driver program can call the value property on the accumulator to access its value
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Broadcast Variables (1)}
\begin{itemize}
	\item {\bf Underlying idea}
	\begin{itemize}
		\item Shared variable allowing the driver to efficiently send a large, \emph{read-only} value to all the worker nodes
	\end{itemize}
	\item {\bf Common uses}
	\begin{itemize}
		\item Send a large, read-only lookup table to all the workers, or even a large feature vector in a machine learning algorithm
		\item It is an enhanced version of Hadoop MapReduce distributed cache
	\end{itemize}
	\item {\bf A note of precaution:}
	\begin{itemize}
		\item For large values to be broadcast, the time to send them over the network can quickly become a bottleneck
		\item It is important to choose a data serialization format that is both fast and compact
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Broadcast Variables (2)}
{\bf Basic work-flow to use broadcast variables:}

\vspace{20pt}

\begin{itemize}
	\item Create a \texttt{Broadcast[T]} by calling \texttt{SparkContext.broadcast} on an object of type T. Any type works as long as it is also \texttt{Serializable}
	\item Access its value with the value property
	\item The variable will be sent to each node only once, and should be treated as \emph{read-only} (updates will not be propagated to other nodes)
\end{itemize}
\end{frame}

\begin{frame}\frametitle{MLLib}
\begin{itemize}
	\item {\bf Set of machine learning algorithms written on top of Spark}
	\begin{itemize}
		\item High-quality implementations of standard algorithms
		\item Special data types to manipulate Vectors, Matrices, ...
	\end{itemize}

	\item {\bf Examples of problems that can be addressed with MLLib}
	\begin{itemize}
		\item Classification, regression
		\item Clustering
		\item Collaborative filtering
		\item Dimensionality reduction
	\end{itemize}

	\item {\bf Machine Learning Pipelines}
	\begin{itemize}
		\item Higher-level API built on top of DataFrames
		\item Although it is an important topic, we will not use them in this course
	\end{itemize}
\end{itemize}
\end{frame}