{"nbformat_minor": 0, "nbformat": 4, "cells": [{"source": ["<div>\n", "<h1>Run the cell below to generate the road map (do not modify it)</h1></div>"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": ["%%javascript\n", "var kernel = IPython.notebook.kernel;var thename = window.document.getElementById(\"notebook_name\").innerHTML;var command = \"THE_NOTEBOOK = \" + \"'\"+thename+\"'\";kernel.execute(command);command=\"os.environ['THE_NOTEBOOK'] = THE_NOTEBOOK\";kernel.execute(command);var cell = IPython.notebook.get_cell(2);cell.execute();IPython.notebook.get_cell(3).focus_cell();var x = $('.code_cell');$(x[1]).children('.input').hide();"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 2, "cell_type": "code", "source": ["outputdir = \"/tmp/tools/\"\n", "!mkdir -p $outputdir\n", "!wget \"https://www.dropbox.com/s/4g0pigmro4vo1b4/menutemplate?dl=0\" -O /tmp/tools/menutemplate >> /tmp/toollog 2>&1 \n", "!wget \"https://www.dropbox.com/s/3flttpzhsja8td7/construct_menu.py?dl=0\" -O /tmp/tools/construct_menu.py >> /tmp/toollog 2>&1 \n", "!python /tmp/tools/construct_menu.py \"{THE_NOTEBOOK}.ipynb\" {outputdir}\n", "from IPython.core.display import HTML\n", "output_file_name = outputdir + THE_NOTEBOOK.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\") + \".ipynb.html\"\n", "with open(output_file_name) as fp:\n", "    html = fp.read()\n", "HTML(html)"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["Advances in imaging equipment and automation have led to an overabundance of data on the functioning of the brain. Technologies today can sample brain activity from a large number of neurons in a large region while organisms are actively behaving. For example, by simultaneously recording the electrical activity of every neuron of the mouse brain over an extended period of time, the amount of data generated will create completely new paradigms for biology, that will require the development of tools to extract value from such unprecedented amount of information.\n", "\n", "In this Notebook, we use PySpark and the [Thunder project](https://github.com/thunder-project/thunder), which is developed on top of PySpark, for processing large amounts of time series data in general, and neuroimaging data in particular. We will use these tools for the task of understanding some of the structure of Zebrafish brains, which is a typical (and simple) example used in Neuroimaging. Using Thunder, we will cluster different regions of the brain (representing groups of neurons) to discover patterns of activity as the zebrafish behaves over time.\n", "\n", "**Note**: Please, use the documentation for the [Thunder API](http://docs.thunder-project.org/) to learn the details of function calls!\n", "\n", "\n", "# Goals\n", "\n", "The main goals of this notebook are:\n", "\n", "1. Learn about Thunder and how to use it\n", "2. Revisit the K-Means algorithm and the method for choosing K\n", "3. Learn alternative approaches to improve the results\n", "\n", "\n", "# Steps\n", "1. In section 1, we go though some background concepts that are used in this notebook.\n", "2. Next, in section 2, we will get familiar with Thunder, its methods and its data types, by working on some simple tasks.\n", "3. Finally, in section 3, we will build a model to cluster the neurons of a zebrafish based on their behavior. In this step, we will learn about how to use K-Means when the value of K is unknown. Finally, some tricks to improve the results are introduced."], "cell_type": "markdown", "metadata": {}}, {"source": ["# 1. Background concepts\n", "\n", "In this section, we cover the terminology and the concepts that constitute the domain knowledge for this notebook.\n", "\n", "As it should be well-known, a `pixel` is a combination of \"**pic**ture **el**ement\": digital images can be modeled as simple 2-dimensional (2D) matrices of intensity values, and each element in the matrix is a pixel. In color images, a pixel contains values of red, green, and blue channels. In a grayscale image, the three channels have the same value, such that each pixel is reduced to be a single value.\n", "\n", "A single 2D image is not nearly enough to express 3D objects, which use a **voxel**, representing a value of the 3D image on a regular grid in a three-dimensional space.  A possible technique to work on 3D images is to acquire multiple 2D images of different slices (or `planes`, or `layers`) of a 3D object, and stack them one on top of each other (a z-stack). This ultimately produces a 3D matrix of intensity values, where each value represents a `volume element` or `voxel`.\n", "\n", "![](https://upload.wikimedia.org/wikipedia/commons/b/b4/Voxelgitter.png)\n", "<div style=\"text-align:center;\">This z-stack image has 4 layers. A point is a voxel. It can be determined by the layer's index and the position in that layer.</div>\n", "\n", "In the context of the Thunder package, we use term `image` for `3D-image` or `stack image`. Thunder uses `Image` type to  represent 3D-image. Each `Image` object is a collection of either 2D images or 3D volumes. In practice, it wraps an n-dimensional array, and supports either distributed operations via Spark or local operations via  numpy , with an identical API.\n", "\n", "Stack-images can represent 3D objects, but it can be difficult to take the temporal relationship of the images into account. To do that, we need another data structure that shows the changes of voxels over time. In the Thunder package, the internal `Series` type can be used exactly for this purpose. Each `Series` is a 1D array such that each element is a value of the voxel at a timestamp.\n", "\n", "The most common series data is time series data, in which case the index is time and each record is a different signal, like a channel or pixel.\n", "\n", "We now have sufficient material to start playing with Thunder !!!"], "cell_type": "markdown", "metadata": {}}, {"source": ["# 2. Let's play\n", "\n", "Well, wait a second before we play... Remember, we're going to use Spark to perform some of the computations related to this Notebook. Now, when you spin a Zoe Notebook application (this comment is valid for students at Eurecom), you'll gain access to an individual, small Spark cluster that is dedicated to your Notebook. This cluster has two worker machines, each with 6 cores. As such, a good idea to obtain smooth performance and a balanced load on the workers, is to ```repartition``` your data (i.e., the RDDs you use to represent images or time series).\n", "\n", "In this Notebook we **expect** students to take care of repartitioning, and such care will be compensated by bonus points."], "cell_type": "markdown", "metadata": {}}, {"source": ["## 2.1. Play with Image objects\n", "\n", "### a. Loading image data\n", "\n", "Both `images` and `series` can be loaded from a variety of data types and locations. You need to specify whether data should be loaded in 'local' mode, which is backed by a numpy array, or in 'spark' mode, which is backed by an RDD by using the optional argument `engine`. The argument `engine` can be either `None` for local use or a SparkContext for` distributed use with Spark.\n", "\n", "```python\n", "import thunder as td\n", "\n", "# load data from tif images\n", "data = td.images.fromtif('/path/to/tifs')\n", "\n", "# load data from numpy-arrays\n", "data = td.series.fromarray(somearray)\n", "data_distributed = ts.series.fromarray(somearray, engine=sc)\n", "```\n", "\n", "We can load some example image data by:"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": ["import thunder as td\n", "import numpy as np\n", "\n", "# load some example image data\n", "image_data = td.images.fromexample('fish', engine=sc)\n", "\n", "# print the number of images\n", "print(image_data.count())"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["### b. Inspecting image data"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "\n", "# import two function to draw images easier\n", "from showit import image as draw_image\n", "from showit import tile as draw_tile\n", "\n", "print(\"Shape of the data:\", image_data.shape)\n", "\n", "first_image = image_data.first() # get the values of Image object\n", "# or first_image = image_data[0] # get the Image object\n", "\n", "print(\"Shape of the data of the first image:\", first_image.shape)\n", "\n", "print(\"Data of the first image:\", first_image)\n", "\n", "\n", "# draw the first layer of the first image\n", "draw_image(first_image[0])\n", "\n", "# draw all layers of the first image\n", "draw_tile(first_image)\n", "\n", "# we can use index slices to take images\n", "samples = image_data[0:6]\n", "\n"], "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": ["From the result above, the shape of the loaded data is (20, 2, 76, 87). It means we have total 20  3D images objects. Each image has 2 layers, each layer has size 76x87. \n", "\n", "Note that, although  data  is not itself an array (it can be a kind of RDD), we can index into it using bracket notation, and pass it as input to plotting methods that expect arrays. In these cases, the data will be automatically converted."], "cell_type": "markdown", "metadata": {}}, {"source": ["One of the advantages of working in Python is that we can easily visualize our data stored into Spark RDDs using the Matplotlib library. Function `draw_image` and `draw_tile` that take advantages of Matplotlib are examples."], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 1\n", "\n", "a) Use the function `imgshow` from matplotlib to plot each layer of the first image in `image_data`.\n", "\n", "b) Discuss the choice of parameters you use for the method `imgshow`"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "\n", "img = image_data.first() \n", "# or:\n", "# img = image_data[1]\n", "\n", "# show the first layer\n", "plt.imshow(img[...], interpolation='nearest', aspect='equal', cmap='gray')\n", "plt.title(\"Layer 0 of the first image\")\n", "plt.show()\n", "\n", "# show the second layer\n", "...\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["Then, we can perform operations that aggregate information across images."], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 2\n", "Calculate the standard deviation across all images you have in `image_data` (that is, our dataset). To clarify, let's focus on an individual layer (say the first layer of each image). For every `voxel`, compute the standard deviation of its values across different images for the same layer. Visualize the standard deviation you obtain, for example concerning a single layer (as before, say the first layer).\n", "\n", "HINT 1: to avoid wasting time and energy, make sure you lookup for methods that could help answer the question from the Thunder documentation.\n", "\n", "HINT 2: We can also use function `draw_image(<data>)` to plot an image in a simple way instead of using many statements with matplotlib as before.\n", "\n", "**NOTE:** Comment the image you obtain. What does it mean to display the standard deviation across all images in a single layer?"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "####!@SOLUTION@!####\n", "# calculate standard deviation of images\n", "std_imgs = image_data....\n", "draw_image(...)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["### c. Selecting samples of image data"], "cell_type": "markdown", "metadata": {}}, {"source": ["The Images API offers useful methods for working with large image data. For example, in some cases it is necessary to subsample each image, to make sure we can analyze it efficiently."], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 3\n", "The source code below subsamples image data with different ratios on different dimensions. \n", "\n", "a) Complete the source code to plot the first layer of the first image. \n", "\n", "b) What is the shape of `image_data` before and after subsampling?"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "subsampled = image_data.subsample((1, 5, 5))\n", "# Stride to use in subsampling. If a single int is passed, each dimension of the image\n", "# will be downsampled by this same factor. If a tuple is passed, it must have the same\n", "# dimensionality of the image. The strides given in a passed tuple will be applied to\n", "# each image dimension\n", "plt.imshow(..., interpolation=..., aspect=..., cmap=...) \n", "plt.title(\"Subsampling image\")\n", "plt.show()\n", "print(\"Before subsampling:\", ...)\n", "print(\"After subsampling:\", ...)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["Note that `subsample` is an RDD operation, so it returns immediately. Indeed, we know that in Spark you must apply a RDD action to trigger the actual computation."], "cell_type": "markdown", "metadata": {}}, {"source": ["### d. Converting image data\n", "We can also convert an RDD of images to a RDD of series by:"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": ["seriesRDD = image_data.toseries()\n", "seriesRDD.cache()"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 4\n", "According to your understanding about `Series` objects which was introduced in section 1, what is the shape of `seriesRDD` and its elments ?\n", "\n", "Comment your results, don't just display numbers."], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"answer\">\n", "\n", "PUT YOUR ANSWER HERE !!!\n", "\n", "</div>"], "cell_type": "markdown", "metadata": {}}, {"source": ["For a large data set that will be analyzed repeatedly as a `Series`, it will ultimately be faster and more convienient to save `Images` data to a collection of flat binary files on a distributed file system, which can in turn be read back in directly as a `Series`, rather than repeatedly converting the images to a `Series` object. This can be performed either through a ThunderContext method, `convertImagesToSeries`, or directly on an Images object, as done below:"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": ["# image_data.toseries().tobinary('directory', overwrite=True)\n", "#ts = td.series.frombinary('directory', engine=sc)"], "outputs": [], "metadata": {"scrolled": true, "collapsed": false}}, {"source": ["We will study about `Series` object in the next section."], "cell_type": "markdown", "metadata": {}}, {"source": ["## 2.2. Play with Serises objects\n", "\n", "### a. Loading Series data\n", "\n", "In this section, we use a sample data to explore `Series` objects."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": ["# series_data = td.series.fromexample('fish', engine=sc)\n", "# series_data = td.series.frombinary(path='s3n://thunder-sample-data/series/fish', engine=sc)\n", "series_data = image_data.toseries()"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["### b. Inspecting Series data"], "cell_type": "markdown", "metadata": {}}, {"source": ["`Series_data` is a distributed collection of key-value records, each containing a coordinate identifier and the time series of a single `voxel`. We can look at the first record by using `first()`. It\u2019s a key-value pair, where the key is a tuple of `int` (representing a spatial coordinate within the imaging volume) and the value is an one-dimensional array."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": ["first_series = series_data.first() # get the values of Series object\n", "#first_series = series_data[0] # get a Series object\n", "\n", "print(\"Shape of series:\", series_data.shape)\n", "print(\"The first series:\", first_series)\n", "print(\"Each element in series has\", len(first_series), \"values\")\n", "\n", "# print the 10th value of voxel (0,0,0)\n", "# layer = 0\n", "# coordinator = (0,0) in that layer\n", "print(\"value 10th of voxel (0,0,0):\", np.array(series_data[0,0,0,10]))"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["The loaded series data is a multi-dimensional array. We can access the values of a voxel in time series by using a tuple as above. In our data, each voxel has 20 values corresponding to 20 states at 20 different times."], "cell_type": "markdown", "metadata": {}}, {"source": ["### c. Selecting Series data\n", "Series objects have a 1D index, which can be used to subselect values."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": ["print(\"shape of index:\", series_data.index.shape)\n", "print(\"the first element of a subset\", series_data.between(0,8).first())"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["Values can be selected based on their index:"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": ["print(series_data.select(lambda x: x > 3 and x < 8).index)\n", "print(series_data.select(lambda x: x > 3 and x < 8).first())\n"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 5\n", "Plot the first 20 values of **all** series objects (that is the values of a voxel) in the series data. This means, on the same plot, you should visualize the values each voxel takes in the first 20 time intervals."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "import numpy as np\n", "\n", "# only select the first 20 states of each object\n", "samples = series_data.between(...).tordd().values().collect()\n", "\n", "plt.plot(np.array(samples).T)\n", "plt.show()\n", "\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["Now, another objective we can have is to select specific series objects within the same series data. For example, we can select objects randomly by using function `sample`."], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 6\n", "Let's plot a random subset of the data using the method `sample`. \n", "\n", "Complete the source code below to plot the first 20 values of 30 objects that are selected randomly among those that pass the condition on the standard deviation, using function `sample`."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "\n", "# select 30 objects randomly which have standard deviation > threshold\n", "# Extract random subset of records, filtering on a summary statistic.\n", "examples = series_data.filter(lambda x: ... > 1.0).sample(...)\n", "# only plot first 20 states of each object\n", "plt.plot(...)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["### d. Preprocessing Series data\n", "A `Series` objects has some methods which can be useful in an eventual preprocessing phase.\n", "\n", "For example,`center` subtracts the mean, `normalize` subtracts and divides by a baseline (either the mean, or a percentile)."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": ["examples = series_data.center().filter(lambda x: x.std() >= 10).sample(50)\n", "plt.plot(np.array(examples).T)\n", "plt.show()"], "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 19, "cell_type": "code", "source": ["normalizedRDD = series_data.normalize(method='mean').filter(lambda x: x.std() >= 0.1).sample(50)\n", "plt.plot(np.array(normalizedRDD).T)\n", "plt.show()"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["### e. Computing statistics about Series data\n", "A `Series` can be summarized with statistics both within and across images. To summarize **across records** (the statistic of all voxels at each timestamp), we can do the following:"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 20, "cell_type": "code", "source": ["plt.plot(series_data.normalize().max());\n", "plt.plot(series_data.normalize().mean());\n", "plt.plot(series_data.normalize().min());"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["To summarize **within records**, we can use the `map` method:"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 21, "cell_type": "code", "source": ["means = series_data.map(lambda x: x.mean())\n", "flat_means = means.flatten().toarray()\n", "flat_stdevs = stdevs = series_data.map(lambda x: x.std()).flatten().toarray()\n", "print(\"means:\", flat_means)\n", "print(\"length of means:\", len(flat_means))\n", "print(\"mean of the first series:\", flat_means[0])\n", "print(\"standard deviation of the first series:\", flat_stdevs[0])"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["`means` is now a `Series` object, where the value of each record is the mean across the time series for that voxel.\n", "\n", "Note that in the source code above, we use function `toarray` to return all records to the driver as a numpy array.\n", "\n", "For this `Series`, since the keys correspond to spatial coordinates, we can `pack` the results back into a local array in **driver node**.\n"], "cell_type": "markdown", "metadata": {}}, {"source": ["To look at this array as an image, we can use function `draw_image` as before."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 22, "cell_type": "code", "source": ["# we should recover the shape of means before plotting\n", "# draw the stdandard deviations of series that belong to the first layer\n", "draw_image(flat_means.reshape((2, 76, 87)) [0,:,:])"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["Note that `toarray` is an example of a local operation, meaning that all the data involved will be sent to the Spark driver node. In this case, packing the mean is no problem because its size is quite small. But for larger data sets, this can be **very problematic**. So, it's a good idea to downsample, subselect, or otherwise reduce the size of your data before attempting to pack large image data sets! "], "cell_type": "markdown", "metadata": {}}, {"source": ["### f. Identifying correlations\n", "\n", "In several problem domains, it may also be beneficial to assess the similarity between a designated signal (time series) and another signal of interest by measuring their correlation. For example, say we have two time series corresponding to the consumption of Coca Cola and Pepsi, it would perhaps be interesting to verify whether behavioural patterns are similar for both brands over time.<br>\n", "\n", "Simply as a proof of concept, we shall compare our data to a random signal and we expect that, for a random signal, the correlation should be low. The signal can be stored as a numpy array or a MAT file containing the signal as a variable. Note that the size of the signal must be equal to the size of each `Series` element."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 23, "cell_type": "code", "source": ["from numpy import random\n", "signal = random.randn(len(first_series))\n", "print(\"The correlation of the first element with random signal:\" , series_data.correlate(signal).first())\n", "\n", "first_element = series_data.first()\n", "corr = series_data.correlate(np.array(first_element)).first()\n", "print(\"The correlation of the first element with itselft:\", corr)"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["# 3. Usecase"], "cell_type": "markdown", "metadata": {}}, {"source": ["## 3.1. Context\n", "Neurons have a variety of biochemical and anatomical properties. Classification methods are thus needed for clarification of the functions of neural circuits as well as for regenerative medicine. In this usecase, we want to categorize the neurons in a fish brain, based on their behavior. The behavior of a neuron can be expressed by the change of its states. The activies of the brains are captured over time into images.\n", "\n", "Neurons have a variety of biochemical and anatomical properties. Classification methods are thus needed for clarification of the functions of neural circuits as well as for regenerative medicine. In this usecase, we want to categorize the neurons in a fish brain, based on their behavior. The behavior of a neuron can be expressed by the change of its states. The activies of the brains are captured over time into images.\n", "\n", "In this notebook,  we use K-Means, a well known clustering algorithm which is also familiar to you, as it was introduced during the last lecture on anomaly detection.\n", "\n", "## 3.2 Data\n", "The dataset we will use is the time series data which we played with in the previous section. Refer to section 2 if you want to duplicate the code to load such data.\n", "\n", "## 3.3.  Building model\n", "### a. Importing required modules"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 24, "cell_type": "code", "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "from pyspark.mllib.clustering import KMeans, KMeansModel\n", "from matplotlib.colors import ListedColormap"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["### b. Loading & inspecting the data"], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 7\n", "Load example series data from `fish`, then normalize and cache it to speed up repeated queries. Print the dimensional information of the loaded data."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "####!@SOLUTION@!####\n", "# we must normalize it to get best clustering\n", "data = td.....normalize()\n", "\n", "# cache it to speed up related queries\n", "data.cache()\n", "\n", "# check the dimensions of data\n", "print (...)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 8\n", "When studying the properties of large data set, we often take a small fraction of it. We have many strategies to select this subset, such as selecting randomly, selecting elements that has the standard deviation bigger than a threshold, or mixing the conditions.\n", "In this notebook, we will use the second method as a small demonstration.\n", "\n", "In order to choose a good value for the threshold of standard deviation, we should compute the stddev of each series and plot a histogram of a 10% sample of the values.\n", "\n", "Complete the source code below to compute the standard deviation of series in data. Plot the histogram of it and discuss it in details. In your opinion, what should be the best value for the threshold ?"], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["```python\n", "# calculate the standard deviation of each series\n", "# then select randomly 10% of value to plot the histogram\n", "stddevs = (data\n", "           ...\n", "           ...\n", "          )\n", "\n", "# plot the histogram of 20 bins\n", "plt....\n", "plt.show()\n", "\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 9\n", "Extract some samples just to look at the typical structure of the time series data.\n", "The objects are selected randomly, and has the standard deviation bigger than the threshold which you picked in question 8.\n", "Plot the samples and discuss your obtained figure."], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["```python\n", "# sample 50 objects of the data randomly base on the standard deviation\n", "examples = data....\n", "\n", "# plot the sample data\n", "plt.plot(...)\n", "plt.show()\n", "\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["### c. Clustering series\n", "In this section, we will use K-means to cluster the series. In other words, we cluster the voxels based on the their behavior. Currently, we have no clue about how many groups `K` of neural behavior. To this end, instead of choosing a single value K, we use multiple values, build model with each `K` and compare the resulting error values. After that, we can choose the best value of `K`. "], "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 10\n", "\n", "Complete the source below to build multiple models coresponding to multiple values of `K` using algorithm KMeans of Thunder.\n", "\n", "a) Comment the structure of the code. Precisely, focus on the `for` loop, and state what is parallel and what is not.\n", "\n", "b) Can you modify the structure of the code such that you use the most of the parallelization capabilities of Spark?"], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["```python\n", "# declare the possible values of K\n", "ks = [5, 10, 15, 20, 30, 50, 100, 200]\n", "\n", "# convert series data to rdd of values\n", "training_data = data.tordd().map(lambda x: np.array(x[1]) ).cache()\n", "    \n", "def buildModels(data):\n", "    # declare the collection of models\n", "    models = [] \n", "\n", "    # build model for each K and append to models\n", "    for k in ks:    \n", "        models.append(KMeans(...).fit(...)) \n", "    return models\n", "\n", "models = buildModels(data)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["### d. Testing models & choosing the best one\n", "\n", "Next, we evaluate the quality of each model. We use two different error metrics on each of the clusterings. \n", "\n", "* The first is the sum across all time series of the Euclidean distance from the time series to their cluster centroids. \n", "\n", "* The second is a built-in metric of the `KMeansModel` object."], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 11\n", "a) Write function `model_error_1` to calculate the sum of Squared Euclidean Distance from the Series objects to their clusters centroids.\n", "\n", "b) Comment the choice of the error function we use here. Is it a good error definition?"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "from scipy.spatial.distance import cdist\n", "\n", "# calculate the Euclidean distance\n", "# from each time series to its cluster center\n", "# and sum all distances\n", "def model_error_1(data, model):\n", "    ...\n", "    return data....\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 12\n", "a) Write function `model_error_2` to calculate the total of similarity of `Series` objects based on how well they match the cluster they belong to, and then calculate the error by inverse the total similarity.\n", "\n", "b) Similarly to the previous question, comment the choice of the similarity function."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "# calculate the total of similarity of the model on timeseries objects\n", "# and calculate the error by inverse the total similarity\n", "\n", "# Estimate similarity between a data point and the cluster it belongs to.\n", "def similarity(centers, p):\n", "    if np.std(p) == 0:\n", "        return 0\n", "    return np.corrcoef(centers[np.argmin(cdist(centers, np.array([p])))], p)[0, 1]\n", "\n", "\n", "def model_error_2(data, model):\n", "    return 1. / ...\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 13\n", "Plot the error of the models along with the different values of K in term of different error metrics above. From the figure, in your opinion, what is the best value for `K` ? Why ?"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "def testAndPlotTheResult(data, models):\n", "    # compute the error metrics for the different resulting clusterings\n", "    \n", "    # errors of models when using function Sum Square Distance Error\n", "    errors_1 = np.asarray(...)\n", "    \n", "    # error of models when using similarity\n", "    errors_2 = np.asarray(...)\n", "\n", "    # plot the errors with each value of K\n", "    plt.plot(\n", "        ks, errors_1 / errors_1.sum(), 'k-o',\n", "        ks, errors_2 / errors_2.sum(), 'b:v')\n", "    plt.show()\n", "    \n", "testAndPlotTheResult(training_data, models)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"answer\">\n", "\n", "PUT YOUR ANSWER HERE !!!\n", "\n", "</div>"], "cell_type": "markdown", "metadata": {}}, {"source": ["Determining the optimal $k$ is particularly troublesome for the $k$-Means algorithm because error measures based on distance decrease monotonically as $k$ increases. This arises because when $k$ is increased, each cluster is decomposed into more and more clusters, such that each point becomes closer to its cluster mean. In fact, in the extreme case where $k=N$, each point will be assigned to its own cluster, and all distances are reduced to nil. Cross-validation or using holdout data is also unlikely to be particularly effective in this case.<br>\n", "\n", "To this end, it is often worth assessing a model by measuring its impact on the overall aim of carrying out the clustering. For example, if we are carrying out $k$-means for grouping customers having similar taste and purchase history with the ultimate intent of making recommendations to customers, our objective function should measure how effective the recommendations are (perhaps using holdout data). An appealing aspect of using such a metric is that it is no longer guaranteed to behave monotonically with respect to $k$. We shall investigate this further in Question 20."], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 14\n", "Plot the centroids of the best model. Do you think that the result is good ?"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "# plot the best performing model\n", "bestModel = models[...]\n", "plt.plot(...)\n", "plt.show()\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["### e. Visualizing the result\n", "We can also plot an image of labels of neurons, such that we can visualize the group of each neuron."], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 15\n", "Complete the source code below to visualize the result of clustering."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "# predict the nearest cluster id for each voxel in Series\n", "labels = bestModel.predict(...)\n", "\n", "# collect data to the driver\n", "imgLabels = labels...\n", "\n", "# consider the voxel of the first layers\n", "draw_image(imgLabels[:,:,0])\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["With the default color scheme, this figure is quite difficult to understand and to distinguish the groups according to their similar colors. So, we should have a smater color selection. The fact is, when we do clustering, it is often the case that some centers are more similar to one another, and it can be easier to interpret the results if the colors are choosen based on these relative similarities. The method `optimize` tries to find a set of colors such that similaries among colors match similarities among an input array (in this case, the cluster centers). The optimization is non-unique, so you can run multiple times to generate different color schemes."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 34, "cell_type": "code", "source": ["from numpy import arctan2, sqrt, pi, abs, dstack, clip, transpose, inf, \\\n", "    random, zeros, ones, asarray, corrcoef, allclose, maximum, add, multiply, \\\n", "    nan_to_num, copy, ndarray, around, ceil, rollaxis\n", "\n", "# these functions below are inspired mainly from Thunder-Project source code, v.0.6\n", "# url: https://raw.githubusercontent.com/thunder-project/thunder/branch-0.6/thunder/viz/colorize.py\n", "\n", "# Optimal colors based on array data similarity.\n", "def optimize_color(mat):\n", "        mat = np.asarray(mat)\n", "\n", "        if mat.ndim < 2:\n", "            raise Exception('Input array must be two-dimensional')\n", "\n", "        nclrs = mat.shape[0]\n", "\n", "        from scipy.spatial.distance import pdist, squareform\n", "        from scipy.optimize import minimize\n", "\n", "        distMat = squareform(pdist(mat, metric='cosine')).flatten()\n", "\n", "        optFunc = lambda x: 1 - np.corrcoef(distMat, squareform(pdist(x.reshape(nclrs, 3), 'cosine')).flatten())[0, 1]\n", "        init = random.rand(nclrs*3)\n", "        bounds = [(0, 1) for _ in range(0, nclrs * 3)]\n", "        res = minimize(optFunc, init, bounds=bounds, method='L-BFGS-B')\n", "        newClrs = res.x.reshape(nclrs, 3).tolist()\n", "\n", "        from matplotlib.colors import ListedColormap\n", "\n", "        newClrs = ListedColormap(newClrs, name='from_list')\n", "\n", "        return newClrs\n", "\n", "# Blend two images together using the specified operator.\n", "def blend(img, mask, op=add):\n", "        if mask.ndim == 3:\n", "            for i in range(0, 3):\n", "                img[:, :, :, i] = op(img[:, :, :, i], mask)\n", "        else:\n", "            for i in range(0, 3):\n", "                img[:, :, i] = op(img[:, :, i], mask)\n", "        return img\n", "\n", "def _prepareMask(mask):\n", "        mask = asarray(mask)\n", "        mask = clip(mask, 0, inf)\n", "\n", "        return mask / mask.max()\n", "    \n", "# Colorize numerical image data.\n", "def transform(cmap, img, mask=None, mixing=1.0):\n", "        from matplotlib.cm import get_cmap\n", "        from matplotlib.colors import ListedColormap, LinearSegmentedColormap, hsv_to_rgb, Normalize\n", "\n", "        img = asarray(img)\n", "        dims = img.shape\n", "\n", "        if cmap not in ['polar', 'angle']:\n", "\n", "            if cmap in ['rgb', 'hv', 'hsv', 'indexed']:\n", "                img = copy(img)\n", "                for i, im in enumerate(img):\n", "                    norm = Normalize(vmin=None, vmax=None, clip=True)\n", "                    img[i] = norm(im)\n", "\n", "            if isinstance(cmap, ListedColormap) or isinstance(cmap, str):\n", "                norm = Normalize(vmin=None, vmax=None, clip=True)\n", "                img = norm(copy(img))\n", "\n", "        if mask is not None:\n", "            mask = _prepareMask(mask)\n", "\n", "        if isinstance(cmap, ListedColormap):\n", "            if img.ndim == 3:\n", "                out = cmap(img)\n", "                out = out[:, :, :, 0:3]\n", "            if img.ndim == 2:\n", "                out = cmap(img)\n", "                out = out[:, :, 0:3]\n", "        else:\n", "            raise Exception('Colorization method not understood')\n", "\n", "        out = clip(out, 0, 1)\n", "\n", "        if mask is not None:\n", "            out = blend(out, mask, multiply)\n", "\n", "        return clip(out, 0, 1)\n", "\n", "\n", "# generate the better color scheme\n", "newClrs = optimize_color(bestModel.centers)\n", "plt.gca().set_color_cycle(newClrs.colors)\n", "plt.plot(np.array(bestModel.centers).T);\n", "\n", "# draw image with the new color scheme\n", "brainmap = transform(newClrs, imgLabels[0,:,:])\n", "draw_image(brainmap)\n"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["### f. Improving the result by removing noise\n", "One problem with what we've done so far is that clustering was performed on all time-series without data pre-processing. Many of  time-series objects were purely noise (e.g. those outside the brain), and some of the resulting clusters capture these noise signals. A simple trick is to perform clustering after subselecting pixels based on the standard deviation of their time series. First, let's look at a map of the standard deviation, to find a reasonable threshold that preserves most of the relavant signal, but ignores the noise."], "cell_type": "markdown", "metadata": {"collapsed": false}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 16\n", "Try with different threshold of standard deviation to filter the noise. What is the \"best value\" that preserves most of the relavant signal, but ignores the noise ? Why ?"], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "# calculate the standard deviation of each voxel \n", "# then collect to the driver\n", "stdMap = data....\n", "\n", "# here we should try with many different values of threshold \n", "# and choosing the best one\n", "# visualize the map of the standard deviation after filtering\n", "draw_image(stdMap[0,:,:] > ...)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"answer\">\n", "\n", "PUT YOUR ANSWER HERE !!!\n", "\n", "</div>"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 17\n", "Filter your data such that we only keep the voxels that have the standard deviation bigger than the threshold in question 16."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "####!@SOLUTION@!####\n", "from numpy import std\n", "# remove series object that has the standard deviation bigger than a threshold\n", "filtered = data.filter(...).cache()\n", "print(filtered.shape)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 18\n", "Re-train and choose the best models with different values of `K` on the new data."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "models = ...\n", "testAndPlotTheResult(training_data, models)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"answer\">\n", "\n", "PUT YOUR ANSWER HERE !!!\n", "\n", "</div>"], "cell_type": "markdown", "metadata": {}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 19\n", "\n", "a) Plot the centroids of the best model with a smart color selection.\n", "\n", "b) Plot the result of the clustering algorithm by a color map of voxels.\n", "\n", "c) Comment about your figures."], "cell_type": "markdown", "metadata": {}}, {"source": ["```python\n", "bestModel = ...\n", "newClrs = ...\n", "...\n", "...\n", "# predict the nearest cluster id for each voxel in Series\n", "labels = data.map(...)\n", "\n", "# collect data to the driver\n", "imgLabels = labels....\n", "...\n", "...\n", "\n", "draw_image(...)\n", "```"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"comment\">\n", "\n", "PUT YOUR COMMENT HERE !!!\n", "\n", "</div>"], "cell_type": "markdown", "metadata": {}}, {"source": ["### g. Improve the visualization by adding similarity\n", "These maps are slightly odd because pixels that did not survive our threshold still end up colored as something. A useful trick is masking pixels based on how well they match the cluster they belong to. We can compute this using the `similarity` method of `KMeansModel`."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 40, "cell_type": "code", "source": ["sim = data.map(lambda x: similarity(bestModel.centers, x))\n", "\n", "imgSim = sim.toarray()\n", "\n", "# draw the mask\n", "draw_image(imgSim[0,:,:], cmap='gray', clim=(0,1))"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["And, it can be used as a linear mask on the colorization output"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 41, "cell_type": "code", "source": ["brainmap = transform(newClrs, imgLabels[0,:,:], mask=imgSim[0,:,:])\n", "draw_image(brainmap)"], "outputs": [], "metadata": {"collapsed": false}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 20\n", "Since in the usecase we build and test the model from the same data, it can lead to overfitting problems. To avoid that, we can divide the data into training set and testing set. Note that each neuron occurs only one time in the data. So, we can not divide the data by dividing the neurons. Instead, we can divide the states of neurons into two different sets. Let's try with this approach and show the result."], "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": ["![](https://farm2.staticflickr.com/1604/24934700445_833f0a5649_t.jpg)"], "cell_type": "markdown", "metadata": {}}, {"source": ["<div class=\"anchor\"></div>\n", "\n", "#### Question 21\n", "Is using K-Means the best choice for a clustering algorithm? Comment the choice and suggest alternatives. For example, look at [Mixture Models](https://en.wikipedia.org/wiki/Mixture_model) and, if you have time, propose an alternative clustering technique. \n", "\n", "**NOTE**: Mixture models will be covered in the ASI course in greater detail."], "cell_type": "markdown", "metadata": {}}, {"source": ["# 4. Summary\n", "We studied Thunder and its important methods to work with images, such as `Image`, `Series` and how to apply them to a use case. In the use case, we used the K-Means algorithm to cluster the neurons without prior knowledge of what a good choice of K could be. Subsequently, we introduced some techniques for improving the initially obtained results, such as removing noise and considering similarity."], "cell_type": "markdown", "metadata": {}}, {"source": ["# References\n", "Some of the examples in this notebook are inspired from the [documentation of Thunder](http://docs.thunder-project.org/)."], "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": [], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": [], "outputs": [], "metadata": {"collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "3.4.4", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}